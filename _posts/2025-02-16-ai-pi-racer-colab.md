---
layout: post
title: AiPiRacer - Ai-Pi-Racer mit Google Colab trainieren
date: 2025-02-16 15:10:54.000000000 +02:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
  - AI
  - Raspberry Pi
  - RC Car
  - google colab
tags:
  - AI
  - KI
  - Neuronal Network
  - Carduino
  - Raspberry Pi 4
  - 3D Printer
  - DonkeyCar
  - google colab
author: Smon
permalink: "/2025/02/16/AiPiRacerColab/"
---

## Ai-Pi-Racer mit Google Colab trainieren

# Einleitung

Der **Ai-Pi-Racer** nutzt ein **neuronales Netz**, um selbststÃ¤ndig auf einer Rennstrecke zu fahren. Damit das Fahrzeug lernen kann, sich effizient zu bewegen, muss es zunÃ¤chst mit Trainingsdaten versorgt und anschlieÃŸend ein Modell trainiert werden.

Hier kommt **Google Colab** ins Spiel: Eine cloudbasierte Plattform, die es ermÃ¶glicht, Python-Code direkt im Browser auszufÃ¼hren. Da das Training eines neuronalen Netzes viel Rechenleistung erfordert, bietet Colab eine ideale Umgebung, um diesen Prozess zu beschleunigen â€“ insbesondere durch die Nutzung von kostenlosen **GPUs** und **TPUs**.

Mit **Google Colab** kannst du:

âœ… GroÃŸe DatensÃ¤tze verarbeiten und dein Modell trainieren, ohne lokale Ressourcen zu belasten.  
âœ… Direkt mit TensorFlow, PyTorch und anderen Machine-Learning-Frameworks arbeiten.  
âœ… Dein neuronales Netz iterativ verbessern und verschiedene Architekturen testen.  

---

## Google Colab Notebook fÃ¼r den Ai-Pi-Racer

Ich habe ein Google Colab Notebook erstellt, mit dem du direkt dein Modell fÃ¼r den **Ai-Pi-Racer** trainieren kannst.  
Klicke auf den folgenden Link, um das Notebook zu Ã¶ffnen und es in deinem eigenen Google Drive zu speichern:

> **ğŸ”— Mein Google Colab Notebook:** [Hier klicken](https://colab.research.google.com/drive/1w5oP6nInVgHqcRKXCCZjzD_msqsTfMtU?usp=sharing)  

**Hinweis:** Du kannst das Notebook in deinem Google Drive speichern und deine eigenen Trainingsdaten verwenden.


1. **GPU-Laufzeit aktivieren:**  
   - Gehe zu **"Laufzeit" â†’ "Laufzeittyp Ã¤ndern"**  
   - WÃ¤hle **"Hardware-Beschleuniger: GPU"**  
   - Falls mÃ¶glich, stelle sicher, dass eine **T4 GPU** genutzt wird.

2. **AusfÃ¼hren der Skripte:**  
   - Alle Code-BlÃ¶cke mÃ¼ssen **nacheinander** ausgefÃ¼hrt werden, um die nÃ¶tigen **Treiber** und **Software** zu installieren.
   - Erst danach kann das Training des neuronalen Netzes starten.

3. **Session aufzeichnen:**  
   - Du kannst aus deiner Session ein **Video schneiden** und anschlieÃŸend downloaden.
   - Dies ist hilfreich fÃ¼r die spÃ¤tere Analyse deines Trainingsprozesses.

ğŸ‰ **Viel SpaÃŸ beim Ausprobieren und Trainieren deines Ai-Pi-Racers!** ğŸš—ğŸ’¨

---

# Auswertung meines letzten Trainingsverlaufs 

<img src="/assets/2025/02/model_loss_01.png" width="50%" height="50%">

Dieses Diagramm zeigt die **Model Loss**-Kurve deines neuronalen Netzes wÃ¤hrend des Trainings deines Ai-Pi-Racers.  

## Beobachtungen  

1. **Anfangs hoher Verlust**  
   - Zu Beginn (Epoch 0) ist der Verlust (Loss) sowohl fÃ¼r das Trainingsset (**blau**) als auch fÃ¼r das Validierungsset (**orange**) hoch.  
   - Das ist normal, da das Modell zu Beginn noch nicht optimiert ist.  

2. **Schneller Abfall des Loss-Werts**  
   - In den ersten wenigen Epochen sinkt der Loss-Wert rapide, was zeigt, dass das Modell schnell lernt und sich verbessert.  

3. **Konvergenz gegen Ende**  
   - Nach etwa **30â€“40 Epochen** nÃ¤hert sich der Loss-Wert einem stabilen, niedrigen Wert.  
   - Dies deutet darauf hin, dass das Modell weitgehend austrainiert ist und sich nicht mehr stark verbessert.  

4. **Validierungsloss ist stabil und niedrig**  
   - Der **Validierungsloss (orange)** folgt dem **Trainingsloss (blau)** eng, ohne stark zu steigen.  
   - Das ist ein gutes Zeichen, da es bedeutet, dass das Modell nicht Ã¼bertrainiert (**Overfitting**) ist und auch auf neuen Daten gut performt.  

## Fazit  

Dein Modell scheint stabil zu trainieren und zeigt keine Anzeichen von Overfitting. Falls du noch weitere Verbesserungen testen willst, kÃ¶nntest du:  

- Die Anzahl der **Epochen** weiter erhÃ¶hen, falls der Loss noch leicht sinkt.  
- Mit der **Lernrate** spielen (ggf. kleiner machen, falls der Loss noch schwankt).  
- **Datenaugmentation** ausprobieren, um die Robustheit des Modells zu verbessern.  

ğŸš€ **Sieht insgesamt nach einem erfolgreichen Training aus!** ğŸ‰
